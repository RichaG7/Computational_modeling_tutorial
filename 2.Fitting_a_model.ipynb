{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fitting a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining a model, they next step would be to fit this model. Model fitting is a measure of how well the model can predict the values of the actual data. The goal of model fitting is to define the parameters that best define the actual data. In this tuturial, we will focus on a subjects' alpha value.\n",
    "\n",
    "In this tutorial, we will again use functions defined in earlier tutorials. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Think about how to define 'model fit', i.e. when is a model good?\n",
    "2. Computing model fit for a given model\n",
    "3. Model fitting: finding the parameters of the model that yield the best model fit\n",
    "3. Fitting the model for different subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.realpath('.')\n",
    "print(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions from before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choice models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inequity_aversion(params, offer):\n",
    "\n",
    "    # Inequity aversion model with one inequity term (= symmetric) and a money term\n",
    "    payoffs = [offer, 0]\n",
    "    inequities = [(100-offer)-offer, 0]\n",
    "    utilities = payoffs - np.multiply(params[0],inequities)\n",
    "    choice = np.where(utilities == np.max(utilities))[0][0]\n",
    "\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_model(params, offer):\n",
    "    \n",
    "    choice = np.random.randint(0,2)\n",
    "    \n",
    "    return choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simulation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_model(model, data_to_simulate, params = None):\n",
    "    \n",
    "    # Input variables: \n",
    "    # - model: the model that you are using\n",
    "    # - data_to_simulate: the actual subject data\n",
    "    # - params: the parameters (alpha, beta) that will be used for simulating the model. Default is None. \n",
    "    \n",
    "    # Create output dataframe\n",
    "    simulation_results = data_to_simulate.copy()\n",
    "    \n",
    "    # Loop over trials and simulate each trial\n",
    "    for trial in data_to_simulate['trial']:\n",
    "        offer = data_to_simulate.loc[data_to_simulate['trial']==trial, 'offer'].values[0]\n",
    "        predicted_choice = model(params, offer)\n",
    "        # store in output dataframe:\n",
    "        simulation_results.loc[data_to_simulate['trial']==trial,'choice'] = predicted_choice\n",
    "        \n",
    "    # Output: results of the simulation    \n",
    "    return simulation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simulation(simulated_sub_data):\n",
    "    \n",
    "    fig = sns.scatterplot(data = simulated_sub_data, x = 'offer', y = 'choice')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = base_dir + '/Data'\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_dir + '/Study1_UG.csv')\n",
    "# Only use the subject nr, trial, unfairness and choice columns \n",
    "data = data[['sub','trial','unfairness','choice']]\n",
    "# Compute a column 'offer', which is 100 - unfairness of the offer. \n",
    "data['offer'] = 100 - data['unfairness']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.How to define model fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways to fit a model. Let's start with a metric of model fit that you might know from regression: the sum of squared error (SSE). \n",
    "Before we compute the SSE, let's start by visually inspecting the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for a subject\n",
    "sub = 20\n",
    "# Only select the data for that subject \n",
    "sub_data = data.query('sub == %i'%sub)[['trial','offer','choice']]\n",
    "sub_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXERCISE: Plot the subject's data as well as simulated data from the random model side-by-side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, use the previously defined functions to simulate and plot the simulated data. Other helpful packages might be:\n",
    "- plt.subplots: this function enables you to plot different subplots side-by-side\n",
    "- plt.scatter: the best way to visualize this data is by using a scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Compute model fit for a given model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As has been previously described, the model fit describes how wel a model can predict the values of the actual data. It is thus a measure of similarity between the actual data and the data that was simulated by the model. One way of computing model fit is by using the sum of squared error (SSE). \n",
    "The SSE is a measure of variance of the simulated data from the actual data. It is computed by substracting the simulated values from the actual values to find the deviation (or the errors). These errors are then squared. \n",
    "\n",
    "Some advantages of using the SSE are:\n",
    "1. It is absolute: it can integrate positive and negative deviations (as they are squared)\n",
    "2. It is familiar: the SSE is also used in regression\n",
    "3. It is simple\n",
    "4. It allows you to directly compare a point prediction (from your model) and an observation data point (we will work with probability distributions later on).\n",
    "5. It ensures that outliers have a bigger impact on your error, e.g. 1 outlier can drive up SSE more than 3 near points. Maybe that's a good thing, maybe not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compute the model fit for the random model using the SSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First merge the two dataframes (actual data, simulated data) to make sure the offers match up:\n",
    "total_data = sub_data.merge(simulated_data, on = ['trial','offer'], suffixes = ['_subject', '_simulation'])\n",
    "\n",
    "# Then compute the errors by substracting the simulated values from the actual values\n",
    "errors = total_data['choice_subject'] - total_data['choice_simulation']\n",
    "\n",
    "# Then, compute the sum of squared errors:\n",
    "SSE = np.sum(np.square(errors))\n",
    "print('Sum of squared error = %i'%SSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how 'good' or 'bad' the model is. But are the errors in one specific direction? For example, a model that always predicts 'accept' will be correct about 'accept' trials 100% of time time, but always wrong about 'reject' trials. To find out, we can use the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we select the subjects' choice and simulations' choices and count how often they made every decision (1 or 0).\n",
    "# Then, we create a matrix of the subjects' choice by the simulations' choice, which we call the confusion_matrix. \n",
    "confusion_matrix = (total_data[['choice_subject','choice_simulation','trial']]\n",
    "                    .groupby(['choice_subject','choice_simulation']).count()\n",
    "                    .reset_index().pivot(index='choice_subject', columns = 'choice_simulation', values = 'trial'))\n",
    "# We plot the matrix using a heatmap, in which the frequency of overlap between the choices is color coded. \n",
    "sns.heatmap(confusion_matrix, square = True, vmin = 0, vmax = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also compute the number of \"hits\", e.g. the number of cases in which the simulated choices were the same as \n",
    "# the actual choices. \n",
    "total_data['correct'] = total_data['choice_subject'] == total_data['choice_simulation']\n",
    "hits = np.sum(total_data['correct'])\n",
    "print('%i hits'%hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXERCISE: Compute model fit for inequity aversion model\n",
    "Similar to the model fitting of the random model, now compute the model fit and the number of hits for the inequity aversion model. Use the earlier specified functions to simulate data. Choose a random alpha value for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the SSE and the number of hits are perfectly correlated (hits = 20 - SSE), so we can pick just one as our objective function (the measure of model fit). In this tutorial, we will use continue using hits as our measure of model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Model fitting: finding the parameters of the model that yield the best model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As has been described before, the goal of model fitting is to define the parameters that best define the actual data. In the previous exercises, we either used a random model (no parameters) or a randomly chosen alpha value. We will now use model fitting to find the parameters that best fit the subjects behavior. \n",
    "\n",
    "Finding these parameters is often done using a grid search. In a grid search, you \"loop\" through different values of the parameters and compute the fit for every combination of parameters. By doing this, you can thus find a combination of parameters of the model that most accurately describe the actual data. \n",
    "\n",
    "In this tutorial, we will only use the alpha value as a parameter in the inequity aversion model. We will thus loop through different alpha values and compute which alpha value best fits the data for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute the model fit for many different values of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of alphas, ranging from 0 to 10 with steps of 0.1\n",
    "range_of_alphas = np.arange(0,10,.1)\n",
    "\n",
    "# Create a dataframe to store the results of our model fitting in\n",
    "model_results = pd.DataFrame(columns=['alpha','hits'])\n",
    "\n",
    "# Loop through the different alpha values and compute the model fit for that alpha \n",
    "for alpha in range_of_alphas:\n",
    "    \n",
    "    # Simulate the model\n",
    "    simulated_data = simulate_model(inequity_aversion, data_to_simulate, [alpha])\n",
    "    \n",
    "    # Merge observed and simulated data\n",
    "    total_data = sub_data.merge(simulated_data, on = ['trial','offer'], suffixes = ['_subject', '_simulation'])\n",
    "    \n",
    "    # Compute hits\n",
    "    total_data['correct'] = total_data['choice_subject'] == total_data['choice_simulation']\n",
    "    hits = np.sum(total_data['correct'])\n",
    "    \n",
    "    # Store results in the dataframe by appending them \n",
    "    tmp = pd.DataFrame([[alpha,hits]], columns=model_results.columns)\n",
    "    model_results = model_results.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of our different alpha values \n",
    "sns.scatterplot(data = model_results, x = 'alpha', y = 'hits')\n",
    "best_alpha = model_results.query('hits == %i'%np.max(model_results.hits))['alpha'].mean()\n",
    "plt.plot([best_alpha, best_alpha], [0,20], 'r:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows you the number of hits for every alpha. The red line shows the value of alpha where you get the maximum number of hits, i.e. the best 'model fit'!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Fitting the model for different subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can automate the fitting procedure and try it for a group of subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXERCISE: Write a function 'subject_fit' that takes subject data and model as inputs and returns the best alpha\n",
    "Use and adjust the previously written code. The outline for the function is already provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_fit(subject_data, model, min_alpha, max_alpha, alpha_step):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return best_alpha, best_hits, total_data, model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the function works\n",
    "# Load data for a subject\n",
    "sub = 20\n",
    "sub_data = data.query('sub == %i'%sub)[['trial','offer','choice']]\n",
    "sub_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the output \n",
    "best_alpha, best_hits, total_data, model_results = subject_fit(sub_data, inequity_aversion, 0, 10, .1)\n",
    "model_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop over subjects\n",
    "Now, we can loop over multiple subjects and compute the best alpha for every subject. To do this, we use a for loop and the previously defined subject_fit() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to store the results in\n",
    "model_fits = pd.DataFrame(columns=['subject','best_alpha','hits'])\n",
    "# As the dataset is very large, we now only loop through the first 20 subjects. \n",
    "for sub in np.arange(1,21):\n",
    "    print(sub, end = ', ')\n",
    "    # Load data for a subject\n",
    "    sub_data = data.query('sub == %i'%sub)[['trial','offer','choice']]\n",
    "    sub_data.head()\n",
    "    # Fit model\n",
    "    best_alpha, best_hits, total_data, model_results = (\n",
    "        subject_fit(sub_data, inequity_aversion, 0, 10, .1))\n",
    "    # Store\n",
    "    tmp = pd.DataFrame([[sub, best_alpha, best_hits]], columns=model_fits.columns)\n",
    "    model_fits = model_fits.append(tmp).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to inspect the output is by plotting the data. Plot the distribution of 'best_alpha' and 'hits' to see how well our model does for the given best alpha values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: distribution of alphas\n",
    "sns.distplot(model_fits['best_alpha'], bins = np.arange(0, 2, .1), rug = True, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: distribution of number of hits\n",
    "sns.distplot(model_fits['hits'], bins = np.arange(0, 20), kde = False, rug = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now fitted to model using the SSE/number of hits for multiple subjects. Similarly, we can fit other models to find the parameters that best describe the observed data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## During next session, we will:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Talk about different model fit metrics\n",
    "- Talk about different choice rules (Softmax, epsilon-greedy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
